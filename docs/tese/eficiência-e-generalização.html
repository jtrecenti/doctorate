<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 5 Eficiência e generalização | Resolvendo CAPTCHAs</title>
  <meta name="description" content="Tese de doutorado." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 5 Eficiência e generalização | Resolvendo CAPTCHAs" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Tese de doutorado." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 5 Eficiência e generalização | Resolvendo CAPTCHAs" />
  
  <meta name="twitter:description" content="Tese de doutorado." />
  

<meta name="author" content="Julio Trecenti" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="results.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Sobre este livro</a></li>
<li class="chapter" data-level="2" data-path="introdução.html"><a href="introdução.html"><i class="fa fa-check"></i><b>2</b> Introdução</a><ul>
<li class="chapter" data-level="2.1" data-path="introdução.html"><a href="introdução.html#objetivos"><i class="fa fa-check"></i><b>2.1</b> Objetivos</a></li>
<li class="chapter" data-level="2.2" data-path="introdução.html"><a href="introdução.html#resultados-esperados"><i class="fa fa-check"></i><b>2.2</b> Resultados esperados</a></li>
<li class="chapter" data-level="2.3" data-path="introdução.html"><a href="introdução.html#revisão-bibliográfica"><i class="fa fa-check"></i><b>2.3</b> Revisão bibliográfica</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="problema.html"><a href="problema.html"><i class="fa fa-check"></i><b>3</b> Problema</a><ul>
<li class="chapter" data-level="3.1" data-path="problema.html"><a href="problema.html#variantes"><i class="fa fa-check"></i><b>3.1</b> Variantes</a><ul>
<li class="chapter" data-level="3.1.1" data-path="problema.html"><a href="problema.html#áudio"><i class="fa fa-check"></i><b>3.1.1</b> Áudio</a></li>
<li class="chapter" data-level="3.1.2" data-path="problema.html"><a href="problema.html#covariáveis-e-número-de-respostas-variável"><i class="fa fa-check"></i><b>3.1.2</b> Covariáveis e número de respostas variável</a></li>
<li class="chapter" data-level="3.1.3" data-path="problema.html"><a href="problema.html#recaptcha-2.0"><i class="fa fa-check"></i><b>3.1.3</b> reCaptcha 2.0</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>4</b> Solução</a><ul>
<li class="chapter" data-level="4.1" data-path="results.html"><a href="results.html#segmentação-e-classificação"><i class="fa fa-check"></i><b>4.1</b> Segmentação e classificação</a></li>
<li class="chapter" data-level="4.2" data-path="results.html"><a href="results.html#força-bruta"><i class="fa fa-check"></i><b>4.2</b> Força-bruta</a><ul>
<li class="chapter" data-level="4.2.1" data-path="results.html"><a href="results.html#redes-neurais"><i class="fa fa-check"></i><b>4.2.1</b> Redes neurais</a></li>
<li class="chapter" data-level="4.2.2" data-path="results.html"><a href="results.html#a-operação-de-convolução"><i class="fa fa-check"></i><b>4.2.2</b> A operação de convolução</a></li>
<li class="chapter" data-level="4.2.3" data-path="results.html"><a href="results.html#redes-neurais-convolucionais"><i class="fa fa-check"></i><b>4.2.3</b> Redes neurais convolucionais</a></li>
<li class="chapter" data-level="4.2.4" data-path="results.html"><a href="results.html#resultados"><i class="fa fa-check"></i><b>4.2.4</b> Resultados</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="eficiência-e-generalização.html"><a href="eficiência-e-generalização.html"><i class="fa fa-check"></i><b>5</b> Eficiência e generalização</a><ul>
<li class="chapter" data-level="5.1" data-path="eficiência-e-generalização.html"><a href="eficiência-e-generalização.html#próximos-passos"><i class="fa fa-check"></i><b>5.1</b> Próximos passos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="appendix"><span><b>Apêndice</b></span></li>
<li class="chapter" data-level="A" data-path="pacote-decryptr.html"><a href="pacote-decryptr.html"><i class="fa fa-check"></i><b>A</b> Pacote decryptr</a><ul>
<li class="chapter" data-level="A.1" data-path="pacote-decryptr.html"><a href="pacote-decryptr.html#funções-do-decryptr"><i class="fa fa-check"></i><b>A.1</b> Funções do <code>decryptr</code></a><ul>
<li class="chapter" data-level="A.1.1" data-path="pacote-decryptr.html"><a href="pacote-decryptr.html#fluxo-de-utilização"><i class="fa fa-check"></i><b>A.1.1</b> Fluxo de utilização</a></li>
<li class="chapter" data-level="A.1.2" data-path="pacote-decryptr.html"><a href="pacote-decryptr.html#download"><i class="fa fa-check"></i><b>A.1.2</b> Download</a></li>
<li class="chapter" data-level="A.1.3" data-path="pacote-decryptr.html"><a href="pacote-decryptr.html#visualização"><i class="fa fa-check"></i><b>A.1.3</b> Visualização</a></li>
<li class="chapter" data-level="A.1.4" data-path="pacote-decryptr.html"><a href="pacote-decryptr.html#classificação"><i class="fa fa-check"></i><b>A.1.4</b> Classificação</a></li>
<li class="chapter" data-level="A.1.5" data-path="pacote-decryptr.html"><a href="pacote-decryptr.html#carregar-modelo"><i class="fa fa-check"></i><b>A.1.5</b> Carregar modelo</a></li>
<li class="chapter" data-level="A.1.6" data-path="pacote-decryptr.html"><a href="pacote-decryptr.html#resolver-captcha"><i class="fa fa-check"></i><b>A.1.6</b> Resolver captcha</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Resolvendo CAPTCHAs</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="eficiência-e-generalização" class="section level1">
<h1><span class="header-section-number">Capítulo 5</span> Eficiência e generalização</h1>
<p>A modelagem via redes neurais convolucionais apresenta resultados satisfatórios, mas tem dois problemas: eficiência e generalização.</p>
<p>O problema de eficiência está relacionado com o fato de que a quantidade de imagens classificadas necessária para obter bom poder preditivo é alta. A partir de nossos testes, identificamos que são necessários em torno de dez mil imagens classificadas para obter um modelo com taxa de acerto maior que 90%.</p>
<p>Já o problema de generalização implica que um modelo ajustado para um tipo CAPTCHA não funciona para outro, ainda que esses tipos sejam muito similares. Na verdade, esses modelos sofrem do problema de <em>aprender</em> versus <em>decorar</em> <span class="citation">(Zhang et al. <a href="#ref-zhang2016understanding">2016</a>)</span>. Isso significa que pequenas modificações na imagem original, e.g. inclusão de ruído gaussiano na imagem, podem resultar em predições completamente diferentes.</p>
<p>Os dois problemas não são independentes. Se criarmos um modelo que generaliza, é razoável afirmar que a quantidade de dados necessária para se obter bom poder preditivo numa nova imagem se reduz.</p>
<p>A Tabela <a href="eficiência-e-generalização.html#tab:solucoes">5.1</a> mostra algumas possíveis abordagens para resolver esses problemas.</p>
<table>
<caption><span id="tab:solucoes">Tabela 5.1: </span>Possíveis soluções para problemas de eficiência e generalização.</caption>
<thead>
<tr class="header">
<th align="left">Eficiência</th>
<th align="left">Generalização</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Feedback</td>
<td align="left">Ensemble</td>
</tr>
<tr class="even">
<td align="left">Reciclagem</td>
<td align="left">Ruído</td>
</tr>
<tr class="odd">
<td align="left">Enriquecimento</td>
<td align="left"></td>
</tr>
</tbody>
</table>
<p>A <strong>reciclagem</strong> consiste na aplicação de métodos de <em>data augmentation</em> usuais em processamento de imagens. Esses métodos consistem em gerar novas imagens a partir das imagens originais, mas adicionando rotações, reflexões e diferentes níveis de zoom. A vantagem da reciclagem é a possibilidade de aumentar a base de treino sem aumentar a quantidade de classificações manuais, o que em tese aumenta a eficiência do aprendizado do modelo.</p>
<p>A aplicação de <strong>ruídos</strong> na imagem segue o mesmo princípio da reciclagem, mas tem foco na generalização. Ruídos podem ser adicionados através de distorções da imagem, ruídos aleatórios e oclusões. O ruído adiciona robustez nas predições, o que em tese possibilitaria que um modelo implementado para um CAPTCHA específico possa ser utilizado para um caso similar.</p>
<p>A utilização de técnicas de <strong>ensemble</strong> visa compartilhar os parâmetros de um modelo de CAPTCHA em outro modelo. A arquitetura moderna de redes neurais possibilita o encaixe de modelos pré-treinados em novas bases de treino. Por exemplo, é possível aproveitar as camadas de redes convolucionais do captcha RFB como inputs adicionais para modelo do TRT. Esses parâmetros podem ser considerados fixos ou podem entrar na verossimilhança do modelo e ser atualizado. Em tese, isso permitiria a criação de apenas um grande modelo para resolver todos os CAPTCHAs.</p>
<p>O <strong>enriquecimento</strong> surge do fato de que origem de novos parâmetros a serem adicionados a um modelo não precisam ser de CAPTCHAs ajustados anteriormente. Esses parâmetros podem vir de ferramentas genéricas de reconhecimento de caracteres (OCR) ou mesmo de bases de dados de caracteres. <span class="citation">George et al. (<a href="#ref-george2017generative">2017</a>)</span> realizaram essa investigação com resultados satisfatórios e conseguiram reduzir o tramanho da base de treino significativamente.</p>
<p>Um mecanismo de <strong>feedback</strong> é uma técnica usada de aumentar a eficiência do modelo ao adicionar informações ao modelo quando a predição falha. As informações são incluídas no modelo através de técnicas de aprendizado por reforço <span class="citation">(Sutton and Barto <a href="#ref-sutton1998introduction">1998</a>)</span>.</p>
<p>Existem duas formas de implementar mecanismos de feedback: automática e manual.</p>
<p>A forma automática aproveita as vantagens da existência de um <em>oráculo</em> de baixo custo para aumentar o tamanho da base de dados automaticamente. O oráculo é uma função que recebe uma imagem e uma predição e informa se a predição está correta ou incorreta. O oráculo tem custo baixo de utilização pois existe em praticamente todos os sites da internet, pois geralmente o CAPTCHA está associado a um formulário de consulta (e.g. uma consulta processual), que verifica se o CAPTCHA foi corretamente resolvido. O problema do oráculo é que, quando algoritmo erra, não sabemos quais são as letras que foram preditas incorretamente. Por exemplo, num caso com <span class="math inline">\(L=6\)</span> letras e <span class="math inline">\(|\mathcal A|=35\)</span>, a informação que o oráculo passa quando o algoritmo erra é que o valor correto do CAPTCHA não é uma das <span class="math inline">\(36^6\)</span> possibilidades. Além disso, em muitos sites só é possível testar a predição do CAPTCHA uma vez. Isso sugere que a informação do oráculo deve ser aliada a heurísticas para que seja útil.</p>
<p>A forma manual utiliza a análise de humanos para inclusão de informações sobre cortes da imagem e erro das letras <span class="citation">(Bursztein et al. <a href="#ref-bursztein2014end">2014</a>)</span>. Uma pergunta de pesquisa interessante nesse sentido seria: qual é a mínima intervenção suficiente para fazer o modelo aprender? Isso pode ser resolvido testando diversos inputs manuais e comparar o tempo de realização do feedback com o ganho em poder preditivo.</p>
<div id="próximos-passos" class="section level2">
<h2><span class="header-section-number">5.1</span> Próximos passos</h2>
<p>Na tese de doutorado, vamos utilizar reciclagem, adição de ruídos, ensemble e enriquecimento para construir modelos mais eficientes e robustos. Pretendemos testar os impactos dessas técnicas na relação entre tamanho da base de treino e poder preditivo do modelo.</p>
<p>O grande desafio da pesquisa será a investigar a forma automatizada de feedback. Caso seja possível evitar completamente o input humano para resolver os CAPTCHAs, o problema de aprendizado de CAPTCHAs baseados em texto estará completamente resolvido. Se não, vamos estudar quais são os limites da aplicação automatizada e buscar métodos que misturem eficientemente as duas formas de feedback.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-bursztein2014end">
<p>Bursztein, Elie, Jonathan Aigrain, Angelika Moscicki, and John C Mitchell. 2014. “The End Is Nigh: Generic Solving of Text-Based Captchas.” In <em>WOOT</em>.</p>
</div>
<div id="ref-george2017generative">
<p>George, Dileep, Wolfgang Lehrach, Ken Kansky, Miguel Lázaro-Gredilla, Christopher Laan, Bhaskara Marthi, Xinghua Lou, et al. 2017. “A Generative Vision Model That Trains with High Data Efficiency and Breaks Text-Based Captchas.” <em>Science</em> 358 (6368). American Association for the Advancement of Science: eaag2612.</p>
</div>
<div id="ref-sutton1998introduction">
<p>Sutton, Richard S, and Andrew G Barto. 1998. <em>Introduction to Reinforcement Learning</em>. Vol. 135. MIT press Cambridge.</p>
</div>
<div id="ref-zhang2016understanding">
<p>Zhang, Chiyuan, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. 2016. “Understanding Deep Learning Requires Rethinking Generalization.” <em>arXiv Preprint arXiv:1611.03530</em>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="results.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/yihui/bookdown-crc/edit/master/04-final.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["jtrecenti_doctorate_captcha.pdf", "jtrecenti_doctorate_captcha.epub"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
