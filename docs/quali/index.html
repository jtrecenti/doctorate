<!DOCTYPE html>
<html>
  <head>
    <title>Resolvendo Captchas</title>
    <meta charset="utf-8">
    <meta name="author" content="Julio TrecentiOrientador: Victor Fossaluza" />
    <meta name="date" content="2018-09-18" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/rladies-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Resolvendo Captchas
## Apresentação para qualificação
### Julio Trecenti</br>Orientador: Victor Fossaluza
### 2018-09-18

---




class: middle, inverse

# Contexto

---

# Motivação

&lt;img src="captcha.png" width="60%" style="display: block; margin: auto;" /&gt;

--

- CAPTCHAs são desafios com resolução **fácil para humanos**, mas **difícil para robôs**. 

- Nasceram entre 2000-2002 em Carnegie Mellon para evitar _**spam**_ .

--

- Hoje são usados por muitos sites, inclusive para acesso de **dados públicos**.  

--

- Podemos argumentar que CAPTCHAs representam um **problema geral** da IA. 


---

# Desafio

- Com bases de treino suficientemente grandes, é **fácil** resolver CAPTCHAs.

--

- Gerar bases de treino para **novos** CAPTCHAs é custoso.

--

- **Oráculos** geram bases de treino incompletas com baixo custo.

--

## Questões norteadoras

1. Como usar o que aprendemos em casos **resolvidos** em **novos** casos?
1. Como **aproveitar** a informação do oráculo?

---

# Oráculo

&lt;img src="oraculo.gif" width="90%" style="display: block; margin: auto;" /&gt;

---

# Objetivo

Buscar formas eficientes e gerais de resolver CAPTCHAs de imagens com textos. 

### Objetivos específicos

1. Definir o problema do CAPTCHA e suas variações.
1. Mostrar solução de alta acurácia usando redes neurais convolucionais.
1. Fazer uma ponte entre regressão logística e redes neurais.
1. Implementar uma ferramenta para resolver CAPTCHAs.
1. Discutir e testar diversas abordagens para aprimorar
    - eficiência: como resolver com uma base de treino menor.
    - generalização: como usar um modelo para novos tipos de CAPTCHA.

---

# Objetivo

Buscar formas eficientes e gerais de resolver CAPTCHAs de imagens com textos. 

### Objetivos específicos

1. **Definir o problema do CAPTCHA e suas variações.**
1. **Mostrar solução de alta acurácia usando redes neurais convolucionais.**
1. **Fazer uma ponte entre regressão logística e redes neurais.**
1. **Implementar uma ferramenta para resolver CAPTCHAs.**
1. Discutir e testar diversas abordagens para aprimorar
    - eficiência: como resolver com uma base de treino menor.
    - generalização: como usar um modelo para novos tipos de CAPTCHA.

---

# Ganhos

--

## Presente

- Implementação do pacote `decryptr` na linguagem R para resolver CAPTCHAs.

- Ponte teórica entre modelo de regressão logística e redes neurais convolucionais utilizando notação comum para estatísticos.

- Resolução de novos CAPTCHAs.

--

## Futuro

- Implementação das metodologias mais recentes de forma reprodutível.

- Estudo e validação de novas abordagens para aumentar eficiência e generalização dos algoritmos.

- Investigação do uso de aprendizado por reforço e junção de modelos.

---
class: inverse, middle

# Teoria

---

# Definição

O que queremos?

- Criar uma função `\(g\)` que 
    - recebe uma imagem `\(\mathbf X = \{x_{nmr} \in [0,1]\}_{N\times M \times R}\)` e 
    - retorna um vetor de índices `\(\mathbf y = \{y_j \in \mathbb N\}_{L \times 1}\)`. 

- `\(c_j \in \mathcal A\)`, o alfabeto (e.g. letras e algarismos).

- `\(L\)` é o número de caracteres contidos na imagem (*comprimento* do CAPTCHA).

- `\(y_j\)` indica a presença de um caractere `\(c_j\)`, `\(j = 1, \dots, L\)`.



---

# Exemplo

&lt;img src="captcha.png" width="40%" style="display: block; margin: auto;" /&gt;

--



- `\(X\)`: ![cap](captcha_small.png), 50x180x1 = 9000 valores

- `\(L = 6\)`

- `\(c_1 =\)` `m` (13ª letra `\(\rightarrow\)` 13º elemento) `\(,\dots,c_6 =\)` `5` (6º número `\(\rightarrow\)` 32º elemento)

- `\(y_1 = 13,\dots,y_6 = 32\)`

- `\(g(X) = y = [13\;\; 11\;\; 13\;\; 1\;\; 7 \;\;32]^\top\)`

---

# Variáveis explicativas

As variáveis **explicativas** são retiradas da imagem, uma matriz `\(\mathbf X = \{x_{ijk}\}_{N\times M \times R}\)`, em que 

- `\(N\)` é o número de linhas, 
- `\(M\)` é o número de colunas e 
- `\(R\)` é o número de *cores*, ou *canais*. 

O elemento `\(x_{nm\cdot}\)` é denominado *pixel*.

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="matrix-rgb.png" alt="Pratap Singh, Bhupendra" width="1133" /&gt;
&lt;p class="caption"&gt;Pratap Singh, Bhupendra&lt;/p&gt;
&lt;/div&gt;

---

# Variável resposta

A **resposta** `\(\mathbf y \in \mathbb \{1, \dots, |\mathcal A|\}^L\)` é um vetor de índices de tamanho fixo. 

- Cada elemento de `\(\mathbf y\)` representa um elemento do alfabeto `\(\mathcal A\)`.

--

## Função objetivo

- Obter `\(g\)` capaz de mapear `\(\mathbf y\)` a partir de uma nova imagem `\(\mathbf X\)`

- Depende de uma amostra de imagens `\(\mathbf X_1, \dots, \mathbf X_S\)`, corretamente classificadas através do vetor `\(\mathbf y_1, \dots, \mathbf y_S\)`. 

- A tarefa é obter uma estimativa `\(\hat g\)` para a função `\(g\)` que minimiza

$$
R(g) = \mathbb E[\mathbb I(g(\mathbf X) \neq \mathbf Y)] = \mathbb P(g(\mathbf X) \neq \mathbf Y))
$$

para novas observações de `\(X\)` e `\(Y\)`.

---

# De GLM a redes neurais

&lt;img src="glm.png" width="70%" style="display: block; margin: auto;" /&gt;

---

# Exemplo: regressão logística

Componente aleatório

`$$Y_i|x \sim \text{Bernoulli}(\mu_i)$$`

Componente sistemático

`$$\eta_i = \alpha + \sum_{j=1}^px_{ij}\beta_j$$`

Função de ligação

`$$g(\mu_i) = \log\left(\frac{\mu_i}{1-\mu_i}\right)$$`

Ligando os componentes

`$$\mu_i = g^{-1}(\eta_i) = \frac{1}{1+e^{-\eta_i}}$$`

---

# Deviance

A log-verossimilhança é dada por

`$$l(\boldsymbol \beta|\mathbf y) = \sum_{i=1}^n y_i\log(\mu_i) + (1-y_i)\log(1-\mu_i)$$`

Uma forma útil de representar a log-verossimilhança é a partir da *função desvio*, dada por

`$$D(\mathbf y|\boldsymbol \beta) = l(\mathbf y|\mathbf y) - l(\boldsymbol \beta|\mathbf y)$$`

---

# Divergência de Kullback-Leibler

`$$D_{KL}(p||q) = p\log\left(\frac p q\right) + (1-p)\log\left(\frac{1-p}{1-q}\right)$$`

Deviance equivale à divergência de Kullback-Leibler

`$$\begin{aligned}
D(\mathbf y|{ \boldsymbol \beta}) &amp;= \sum_{i=1}^n y_i\log(y_i) + (1-y_i)\log(1-y_i) - \sum_{i=1}^n y_i\log(\mu_i) + (1-y_i)\log(1-\mu_i) \\
&amp;=\sum_{i=1}^ny_i\log\left(\frac{y_i}{\mu_i}\right) + (1-y_i)\log\left(\frac{1-y_i}{1-\mu_i}\right) \\
&amp;= \sum_{i=1}^n D_{KL}(y_i||\mu_i) \\
&amp;= D_{KL}(\mathbf y||{\boldsymbol\mu}).
\end{aligned}$$`

---

# Rede neural

- Componente aleatório: é equivante à divergência KL / Deviance.

--

- Componente sistemático: viés e matriz de pesos. Com uma unidade de ativação:

`$$b^1 = \alpha^1\;\;\;\;\;\;\; W^1 = \left[\begin{array}{cc}\beta^1_{1}\\ \vdots \\ \beta^1_{p}\;\end{array}\right]^\top$$`

--

Com duas unidades de ativação:

`$$b^1 = \left[\begin{array}{cc}\alpha^1_1\\ \alpha^1_2\end{array}\right]\;\;\;\;\;\;\; W^1 = \left[\begin{array}{cc}\beta^1_{1,1}\;\beta^1_{1,2}\\ \vdots \\ \beta^1_{p,1}\;\beta^1_{p,2}\end{array}\right]^\top$$`

--

- Função de ligação: função de ativação

`$$Z^1 = g(W^1X^\top + b^1)$$`

---

# Conclusões preliminares

- Um modelo de regressão logística é equivalente a uma rede neural com uma camada e uma unidade de ativação

--

- Podemos usar `\(Z^1\)` como uma nova matriz `\(X\)`, iterativamente

--

- A forma usual de minimizar a deviance é diferente nos dois modelos:


- A regressão logística utiliza Newton-Raphson/Fisher Scoring (segunda derivada)

`$$\beta_{new} = \beta - \mathcal I_\beta^{-1}\mathcal U_\beta,$$`

onde 

- `\(\mathcal U_\beta\)` é o vetor escore (gradiente) e

- `\(\mathcal I_\beta\)` é a matriz de Informação (esperança da Hessiana).

--

- A rede neural utiliza descida de gradiente (primeira derivada)

`$$\beta_{new}=\beta - \alpha\,\mathcal U_\beta$$`

mais: http://bit.ly/athos-menor-dl

---

# Solução atual

- Utilizamos redes neurais convolucionais

--

- O modelo aplica uma operação diferente de `\(X\beta\)` para produzir `\(\eta\)`, que explora a proximidade entre pixels. Essa operação é chamada convolução. 

Por exemplo, considere a matriz de pesos 3x3

`$$W = \left[\begin{array}{rrr}-1&amp;-1&amp;-1\\0&amp;0&amp;0\\1&amp;1&amp;1\end{array}\right]$$`

--

E a janela 3x3 a partir do ponto `\((12,16)\)` da matriz `\(X\)`

`$$X_{12,16} = \left[\begin{array}{rrr}
0.98 &amp; 0.53 &amp; 0.79 \\ 
0.97 &amp; 0.99 &amp; 1.00 \\ 
0.98 &amp; 1.00 &amp; 1.00 
\end{array}\right]$$`

--

A convolução de `\(X\)` por `\(W\)` no ponto `\((12,16)\)` é dada por

`$$\begin{aligned}
(X_{12,16} *w )_{12,16}
&amp;= w_{1,1}x_{11,15} + w_{1,2}x_{11,16} + w_{1,3}x_{11,17} + \\
&amp;+ w_{2,1}x_{12,15} + w_{2,2}x_{12,16} + w_{2,3}x_{12,17} + \\
&amp;+ w_{3,1}x_{13,15} + w_{3,2}x_{13,16} + w_{3,3}x_{13,17}
\end{aligned}$$`

---

# Resultados


&lt;table&gt;
&lt;tr&gt; &lt;th&gt;Imagem             &lt;/th&gt; &lt;th&gt;Nome&lt;/th&gt; &lt;th&gt;N&lt;/th&gt;     &lt;th&gt;Taxa de acerto&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt; &lt;td&gt;&lt;img src='rfb.png'&gt;&lt;/td&gt; &lt;td&gt;RFB&lt;/td&gt;  &lt;td&gt;27000&lt;/td&gt; &lt;td&gt;98%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt; &lt;td&gt;&lt;img src='trt.png'&gt;&lt;/td&gt; &lt;td&gt;TRT&lt;/td&gt;  &lt;td&gt;410&lt;/td&gt; &lt;td&gt;98%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt; &lt;td&gt;&lt;img src='tjmg.jpeg'&gt;&lt;/td&gt; &lt;td&gt;TJMG&lt;/td&gt;  &lt;td&gt;10000&lt;/td&gt; &lt;td&gt;100%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt; &lt;td&gt;&lt;img src='rsc.png'&gt;&lt;/td&gt; &lt;td&gt;RSC&lt;/td&gt;  &lt;td&gt;11000&lt;/td&gt; &lt;td&gt;99%&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt; &lt;td&gt;&lt;img src='cadesp.png'&gt;&lt;/td&gt; &lt;td&gt;CADESP&lt;/td&gt;  &lt;td&gt;10000&lt;/td&gt; &lt;td&gt;98%&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;



---
class: inverse, middle

# Problemas e próximos passos

---

# Problemas e próximos passos

Possíveis soluções para problemas de eficiência e generalização:

&lt;table&gt;
&lt;caption&gt;&lt;/caption&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; Eficiência &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; Generalização &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Reciclagem &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Ruído &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Enriquecimento &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Ensemble &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Feedback &lt;/td&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

--

- **reciclagem**: aplicar métodos de *data augmentation*.

--

- **ruído**: mesmo princípio da reciclagem, mas tem foco na generalização. 

--

- **enriquecimento**: Aproveitar ferramentas (OCR) e bases de caracteres. 

--

- **ensemble**: usar parâmetros ajustados de um modelo em outro. 

--

- **feedback**: Aproveitar o oráculo com alguma técnica de aprendizado por reforço.

---
class: inverse

# Agradecimentos

- Victor Fossaluza
- Rafael Izbicki
- Rafael Stern
- **Curso-R**: Athos, Caio, Daniel, Fernando, William


&lt;a href="https://curso-r.com"&gt;

&lt;img src="logo-curso-2.png" width="20%" style="display: block; margin: auto;" /&gt;

&lt;/a&gt;

---

# Obrigado!

## Tese

- https://github.com/jtrecenti/doctorate

## `decryptr`

- https://github.com/decryptr/decryptr

- https://decryptr.netlify.com/


&lt;a href="https://github.com/decryptr"&gt;

&lt;img src="22989908.jpeg" width="20%" style="display: block; margin: auto;" /&gt;

&lt;/a&gt;
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
