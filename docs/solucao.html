<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Quebrando CAPTCHAs</title>
  <meta name="description" content="Tese de doutorado.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Quebrando CAPTCHAs" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Tese de doutorado." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Quebrando CAPTCHAs" />
  
  <meta name="twitter:description" content="Tese de doutorado." />
  

<meta name="author" content="Julio Trecenti">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="problema.html">
<link rel="next" href="resultados.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="introducao.html"><a href="introducao.html"><i class="fa fa-check"></i><b>2</b> Introdução</a><ul>
<li class="chapter" data-level="2.1" data-path="introducao.html"><a href="introducao.html#objetivos"><i class="fa fa-check"></i><b>2.1</b> Objetivos</a></li>
<li class="chapter" data-level="2.2" data-path="introducao.html"><a href="introducao.html#resultados-esperados"><i class="fa fa-check"></i><b>2.2</b> Resultados Esperados</a></li>
<li class="chapter" data-level="2.3" data-path="introducao.html"><a href="introducao.html#organizacao-do-trabalho"><i class="fa fa-check"></i><b>2.3</b> Organização do trabalho</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="problema.html"><a href="problema.html"><i class="fa fa-check"></i><b>3</b> Problema</a><ul>
<li class="chapter" data-level="3.1" data-path="problema.html"><a href="problema.html#variantes"><i class="fa fa-check"></i><b>3.1</b> Variantes</a><ul>
<li class="chapter" data-level="3.1.1" data-path="problema.html"><a href="problema.html#audio"><i class="fa fa-check"></i><b>3.1.1</b> Áudio</a></li>
<li class="chapter" data-level="3.1.2" data-path="problema.html"><a href="problema.html#covariaveis-e-numero-de-respostas-variavel"><i class="fa fa-check"></i><b>3.1.2</b> Covariáveis e número de respostas variável</a></li>
<li class="chapter" data-level="3.1.3" data-path="problema.html"><a href="problema.html#recaptcha"><i class="fa fa-check"></i><b>3.1.3</b> reCaptcha</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="solucao.html"><a href="solucao.html"><i class="fa fa-check"></i><b>4</b> Solução</a><ul>
<li class="chapter" data-level="4.1" data-path="solucao.html"><a href="solucao.html#segmentacao-e-classificacao"><i class="fa fa-check"></i><b>4.1</b> Segmentação e classificação</a></li>
<li class="chapter" data-level="4.2" data-path="solucao.html"><a href="solucao.html#forca-bruta"><i class="fa fa-check"></i><b>4.2</b> Força-bruta</a><ul>
<li class="chapter" data-level="4.2.1" data-path="solucao.html"><a href="solucao.html#redes-neurais"><i class="fa fa-check"></i><b>4.2.1</b> Redes neurais</a></li>
<li class="chapter" data-level="4.2.2" data-path="solucao.html"><a href="solucao.html#a-operacao-de-convolucao"><i class="fa fa-check"></i><b>4.2.2</b> A operação de convolução</a></li>
<li class="chapter" data-level="4.2.3" data-path="solucao.html"><a href="solucao.html#aplicando-nos-captchas"><i class="fa fa-check"></i><b>4.2.3</b> Aplicando nos captchas</a></li>
<li class="chapter" data-level="4.2.4" data-path="solucao.html"><a href="solucao.html#redes-neurais-convolucionais"><i class="fa fa-check"></i><b>4.2.4</b> Redes neurais convolucionais</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="solucao.html"><a href="solucao.html#eficiencia-e-generalizacao"><i class="fa fa-check"></i><b>4.3</b> Eficiência e generalização</a><ul>
<li class="chapter" data-level="4.3.1" data-path="solucao.html"><a href="solucao.html#feedback"><i class="fa fa-check"></i><b>4.3.1</b> Feedback</a></li>
<li class="chapter" data-level="4.3.2" data-path="solucao.html"><a href="solucao.html#reciclagem"><i class="fa fa-check"></i><b>4.3.2</b> Reciclagem</a></li>
<li class="chapter" data-level="4.3.3" data-path="solucao.html"><a href="solucao.html#ensemble"><i class="fa fa-check"></i><b>4.3.3</b> Ensemble</a></li>
<li class="chapter" data-level="4.3.4" data-path="solucao.html"><a href="solucao.html#section"><i class="fa fa-check"></i><b>4.3.4</b> </a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="resultados.html"><a href="resultados.html"><i class="fa fa-check"></i><b>5</b> Resultados</a></li>
<li class="chapter" data-level="6" data-path="consideracoes-finais.html"><a href="consideracoes-finais.html"><i class="fa fa-check"></i><b>6</b> Considerações finais</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="7" data-path="pacote-decryptr.html"><a href="pacote-decryptr.html"><i class="fa fa-check"></i><b>7</b> Pacote decryptr</a></li>
<li class="chapter" data-level="8" data-path="captchas-em-audio.html"><a href="captchas-em-audio.html"><i class="fa fa-check"></i><b>8</b> CAPTCHAs em áudio</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Quebrando CAPTCHAs</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="solucao" class="section level1">
<h1><span class="header-section-number">Capítulo 4</span> Solução</h1>
<p><span class="citation">(Ahn, Blum, and Langford <a href="#ref-von2002telling">2002</a>)</span> define captchas pela primeira vez</p>
<p><span class="citation">(Von Ahn et al. <a href="#ref-von2003captcha">2003</a>)</span> define um problema de resolver captcha como um problema de inteligência artificial.</p>
<p><span class="citation">(Mori and Malik <a href="#ref-mori2003recognizing">2003</a>)</span> apresenta uma solução rudimentar para o problema a partir de cortes em imagens. O modelo final acerta somente 33% dos casos.</p>
<p><span class="citation">(Yan and El Ahmad <a href="#ref-yan2008low">2008</a><a href="#ref-yan2008low">a</a>)</span> criam um modelo de quebrar captcha baseado em diversas heurísticas.</p>
<p><span class="citation">(Yan and El Ahmad <a href="#ref-yan2008usability">2008</a><a href="#ref-yan2008usability">b</a>)</span> usability issues in CAPTCHA design</p>
<p><span class="citation">(Golle <a href="#ref-golle2008machine">2008</a>)</span> utilizam SVM</p>
<p><span class="citation">(Motoyama et al. <a href="#ref-motoyama2010re">2010</a>)</span> estudam o aspecto economico dos recaptchas</p>
<p><span class="citation">(Bursztein, Martin, and Mitchell <a href="#ref-bursztein2011text">2011</a>)</span> testam varios modelos em 15 captchas diferentes</p>
<p><span class="citation">(Bursztein et al. <a href="#ref-bursztein2014end">2014</a>)</span> mostram um modelo de reinforcement</p>
<div id="segmentacao-e-classificacao" class="section level2">
<h2><span class="header-section-number">4.1</span> Segmentação e classificação</h2>
<p>Um problema de resolver o CAPTCHA diretamente é que a variável resposta <span class="math inline">\(\mathbf y\)</span> tem um número exponencial de combinações. Na formulação do capítulo anterior, nossa resposta é uma palavra de <span class="math inline">\(L\)</span> caracteres, sendo que cada caractere <span class="math inline">\(c_j\)</span> pode ter <span class="math inline">\(|\mathcal A|\)</span> valores. Nessa construção, o total de combinações é <span class="math inline">\(|\mathcal A|^L\)</span>.</p>
<p>Por exemplo, um CAPTCHA com <span class="math inline">\(L=6\)</span> letras e <span class="math inline">\(|\mathcal A| = 36\)</span> possibilidades em cada letra (26 letras do alfabeto e 10 algarismos), possui um total de 2.176.782.336 (&gt; 2 bilhões) combinações. Modelar essas imagens diretamente através de uma única variável resposta categórica é inviável.</p>
<p>Por isso, uma forma de resolver CAPTCHAs é separando o problema em duas tarefas: segmentar e classificar. A tarefa de segmentação consiste em receber uma imagem com várias letras e detectar pontos de corte, separando-a em várias imagens de uma letra. Já a classificação consiste em receber uma imagem com uma letra e identificar o caractere correspondente. Nesse caso, a resposta é reduzida para <span class="math inline">\(|\mathcal A|\)</span> categorias, que cresce linearmente e, portanto, tratável.</p>
<p>[img-fluxo]</p>
<p>A literatura mostra através de estudos empíricos que a tarefa de segmentar é mais difícil do que a tarefa de classificar <span class="citation">(Bursztein et al. <a href="#ref-bursztein2014end">2014</a>)</span>. Isso acontece porque o problema de classificação de letras segmentadas é similar ao problema de reconhecimento de caracteres (<em>Optical Character Recognition</em>, OCR), que é amplamente estudado e pode ser considerado resolvido. A segmentação, no entanto, é um problema em aberto e faz parte da literatura de oclusão de objetos em visão computacional.</p>
<p>Por esse motivo, os desenvolvedores de CAPTCHAs de imagens baseadas em texto têm explorado métodos de dificultar a segmentação. As principais formas são i) colar os caracteres e ii) adicionar linhas ligando os dígitos. Essas técnicas são combinadas com a adição de ruído e distorção de caracteres para compor a imagem final.</p>
<p>Vamos usar como exemplo o CAPTCHA do Tribunal de Justiça de Minas Gerais (TJMG). Nesse caso, temos <span class="math inline">\(L=4\)</span> e <span class="math inline">\(|\mathcal A|=10\)</span>, apenas os dez algarismos.</p>
<p>A Figura <a href="solucao.html#fig:tjmg1">4.1</a> mostra um exemplo do captcha do TJMG. Podemos notar a utilização de distorção de catacteres e adição de linhas ligando os dígitos como formas de evitar a resolução automática.</p>
<div class="figure"><span id="fig:tjmg1"></span>
<img src="jtrecenti_doctorate_captcha_files/figure-html/tjmg1-1.svg" alt="CAPTCHA do TJMG." width="384" />
<p class="caption">
Figura 4.1: CAPTCHA do TJMG.
</p>
</div>
<p>Nesse caso, é podemos resolver o problema da segmentação realizando cortes fixos na imagem. Podemos também limitar os eixos <code>x</code>, tirando os espaços vazios à esquerda e à direita e <code>y</code>, removendo espaços superiores e inferiores. Por último, transformamos a imagem em escala de cinza. O resultado dessas operações de pré-processamento estão na Figura <a href="solucao.html#fig:tjmg2">4.2</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">op &lt;-<span class="st"> </span>graphics<span class="op">::</span><span class="kw">par</span>(<span class="dt">mar =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">4</span>))
arq_captcha <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">read_captcha</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">first</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">with</span>(x) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>magrittr<span class="op">::</span><span class="kw">extract</span>(<span class="op">-</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">7</span>, <span class="dv">34</span><span class="op">:</span><span class="kw">dim</span>(.)[<span class="dv">1</span>]), <span class="op">-</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">06</span>, <span class="dv">107</span><span class="op">:</span><span class="kw">dim</span>(.)[<span class="dv">2</span>]), <span class="ot">TRUE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>grDevices<span class="op">::</span><span class="kw">as.raster</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>graphics<span class="op">::</span><span class="kw">plot</span>()
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="dv">20</span> <span class="op">*</span><span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">4</span>, <span class="dt">col =</span> <span class="st">&#39;red&#39;</span>)
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">26</span>), <span class="dt">col =</span> <span class="st">&#39;blue&#39;</span>)</code></pre></div>
<div class="figure"><span id="fig:tjmg2"></span>
<img src="jtrecenti_doctorate_captcha_files/figure-html/tjmg2-1.svg" alt="CAPTCHA do TJMG após segmentação." width="384" />
<p class="caption">
Figura 4.2: CAPTCHA do TJMG após segmentação.
</p>
</div>
<p>O resultado são cinco imagens de dimensões <code>26x20</code>, associadas a cada caractere. O próximo passo é transformar o banco de dados num formato tratável por modelos tradicionais de regressão. Para isso, colocamos cada pixel em uma coluna da nossa base de dados. No caso do TJMG, cada CAPTCHA gera uma tabela de 5 linhas e 520 (<code>26 * 20</code>) colunas. A Tabela <a href="solucao.html#tab:imgsep">4.1</a> mostra as primeiras seis colunas dessa base.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">arq_captcha <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">read_captcha</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">first</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">with</span>(x) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>magrittr<span class="op">::</span><span class="kw">extract</span>(<span class="op">-</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">7</span>, <span class="dv">34</span><span class="op">:</span><span class="kw">dim</span>(.)[<span class="dv">1</span>]), <span class="op">-</span><span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">06</span>, <span class="dv">107</span><span class="op">:</span><span class="kw">dim</span>(.)[<span class="dv">2</span>]), <span class="ot">TRUE</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>tibble<span class="op">::</span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>tibble<span class="op">::</span><span class="kw">rownames_to_column</span>(<span class="st">&#39;y&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>tidyr<span class="op">::</span><span class="kw">gather</span>(x, value, <span class="op">-</span>y) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">mutate_at</span>(dplyr<span class="op">::</span><span class="kw">vars</span>(x, y), dplyr<span class="op">::</span><span class="kw">funs</span>(readr<span class="op">::</span>parse_number)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">mutate</span>(<span class="dt">letra =</span> (x <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%/%</span><span class="st"> </span><span class="dv">20</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">x =</span> x <span class="op">-</span><span class="st"> </span>(letra <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="dv">20</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">mutate_at</span>(dplyr<span class="op">::</span><span class="kw">vars</span>(x, y), dplyr<span class="op">::</span><span class="kw">funs</span>(<span class="kw">sprintf</span>(<span class="st">&#39;%02d&#39;</span>, .))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>tidyr<span class="op">::</span><span class="kw">unite</span>(xy, x, y) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>tidyr<span class="op">::</span><span class="kw">spread</span>(xy, value, <span class="dt">sep =</span> <span class="st">&#39;&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">mutate</span>(<span class="dt">y =</span> <span class="kw">c</span>(<span class="st">&#39;7&#39;</span>, <span class="st">&#39;3&#39;</span>, <span class="st">&#39;2&#39;</span>, <span class="st">&#39;4&#39;</span>, <span class="st">&#39;6&#39;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(y, dplyr<span class="op">::</span><span class="kw">everything</span>(), <span class="op">-</span>letra) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">7</span>) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">mutate_at</span>(dplyr<span class="op">::</span><span class="kw">vars</span>(<span class="op">-</span>y), dplyr<span class="op">::</span><span class="kw">funs</span>(<span class="kw">round</span>(., <span class="dv">3</span>))) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>(<span class="dt">caption =</span> <span class="st">&quot;Base de dados montada a partir de imagem segmentada.&quot;</span>)</code></pre></div>
<table>
<caption><span id="tab:imgsep">Tabela 4.1: </span>Base de dados montada a partir de imagem segmentada.</caption>
<thead>
<tr class="header">
<th align="left">y</th>
<th align="right">xy01_01</th>
<th align="right">xy01_02</th>
<th align="right">xy01_03</th>
<th align="right">xy01_04</th>
<th align="right">xy01_05</th>
<th align="right">xy01_06</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">7</td>
<td align="right">0.769</td>
<td align="right">0.769</td>
<td align="right">0.769</td>
<td align="right">0.769</td>
<td align="right">0.769</td>
<td align="right">0.773</td>
</tr>
<tr class="even">
<td align="left">3</td>
<td align="right">0.005</td>
<td align="right">0.141</td>
<td align="right">0.316</td>
<td align="right">0.430</td>
<td align="right">0.356</td>
<td align="right">0.319</td>
</tr>
<tr class="odd">
<td align="left">2</td>
<td align="right">0.846</td>
<td align="right">0.851</td>
<td align="right">0.830</td>
<td align="right">0.796</td>
<td align="right">0.800</td>
<td align="right">0.842</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="right">0.886</td>
<td align="right">0.886</td>
<td align="right">0.890</td>
<td align="right">0.890</td>
<td align="right">0.890</td>
<td align="right">0.890</td>
</tr>
<tr class="odd">
<td align="left">6</td>
<td align="right">0.925</td>
<td align="right">0.925</td>
<td align="right">0.929</td>
<td align="right">0.929</td>
<td align="right">0.929</td>
<td align="right">0.933</td>
</tr>
</tbody>
</table>
<p>Agora basta rodar o mesmo para toda a base de treino e rodar um modelo. Nesse exemplo, utilizamos uma base de 1500 CAPTCHAs classificados. O resultado após o pré-processamento é uma base com 7500 linhas e 520 colunas. Escolhemos manter 6000 linhas para treino e as 1500 restantes para teste. Utilizamos um modelo de florestas aleatórias para o exemplo <span class="citation">(Breiman <a href="#ref-breiman2001random">2001</a>)</span>.</p>
<p>O resultado do modelo pode ser verificado na Tabela <a href="solucao.html#tab:errosTJMG">4.2</a>, que mostra os observados <em>versus</em> preditos na base de teste. O acerto foi de 99.6% em cada caractere. Assumindo que o erro não depende da posição do caractere no CAPTCHA, o acerto para a imagem completa é de aproximadamente 98%.</p>
<table>
<caption><span id="tab:errosTJMG">Tabela 4.2: </span>Tabela de acertos e erros.</caption>
<thead>
<tr class="header">
<th align="left">y</th>
<th align="left">0</th>
<th align="left">1</th>
<th align="left">2</th>
<th align="left">3</th>
<th align="left">4</th>
<th align="left">5</th>
<th align="left">6</th>
<th align="left">7</th>
<th align="left">8</th>
<th align="left">9</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0</td>
<td align="left">156</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="left">.</td>
<td align="left">160</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
</tr>
<tr class="odd">
<td align="left">2</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">147</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
</tr>
<tr class="even">
<td align="left">3</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">1</td>
<td align="left">140</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
</tr>
<tr class="odd">
<td align="left">4</td>
<td align="left">.</td>
<td align="left">2</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">150</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
</tr>
<tr class="even">
<td align="left">5</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">153</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
</tr>
<tr class="odd">
<td align="left">6</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">143</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
</tr>
<tr class="even">
<td align="left">7</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">152</td>
<td align="left">.</td>
<td align="left">.</td>
</tr>
<tr class="odd">
<td align="left">8</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">2</td>
<td align="left">1</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">139</td>
<td align="left">.</td>
</tr>
<tr class="even">
<td align="left">9</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">.</td>
<td align="left">1</td>
<td align="left">153</td>
</tr>
</tbody>
</table>
<p>O resultado para o TJMG é bastante satisfatório, mas não generaliza para outros CAPTCHAs. Tome por exemplo o CAPTCHA da Receita Federal (RFB) da Figura <a href="solucao.html#fig:generalize">4.3</a>. Nesse caso, a posição dos caracteres muda significativamente de imagem para imagem, e assim fica difícil cortar em pedaços.</p>
<div class="figure" style="text-align: center"><span id="fig:generalize"></span>
<img src="jtrecenti_doctorate_captcha_files/figure-html/generalize-1.svg" alt="CAPTCHA Receita Federal" width="12%" />
<p class="caption">
Figura 4.3: CAPTCHA Receita Federal
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:generalize"></span>
<img src="jtrecenti_doctorate_captcha_files/figure-html/generalize-2.svg" alt="CAPTCHA Receita Federal" width="12%" />
<p class="caption">
Figura 4.3: CAPTCHA Receita Federal
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:generalize"></span>
<img src="jtrecenti_doctorate_captcha_files/figure-html/generalize-3.svg" alt="CAPTCHA Receita Federal" width="12%" />
<p class="caption">
Figura 4.3: CAPTCHA Receita Federal
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:generalize"></span>
<img src="jtrecenti_doctorate_captcha_files/figure-html/generalize-4.svg" alt="CAPTCHA Receita Federal" width="12%" />
<p class="caption">
Figura 4.3: CAPTCHA Receita Federal
</p>
</div>
<p>A mesma técnica aplicada ao CAPTCHA RFB apresentou acerto de 78.8% do caractere, o que equivale a apenas 23.8% de acerto para toda a imagem. Claro que seria possível melhorar o poder preditivo com ajustes nos hipeparâmetros do modelo, mas o problema essencial nesse caso está na qualidade segmentação, e não na classificação dos caracteres.</p>
<p>Outro problema dessa técnica é que ela é incapaz de trabalhar com CAPTCHAs de comprimento variável. Nesse caso, seria necessário construir um modelo não supervisionado para identificar a posição das letras, o que adiciona um grau a mais de complexidade na resolução do CAPTCHA.</p>
<p>Por isso, faz-se necessária uma abordagem que trabalha com problema completo, sem passar explicitamente pela fase de segmentação. Ao invés de cortar a imagem, vamos extrair detalhes da imagem completa automaticamente e utilizar essas características como variáveis preditoras num modelo de regressão. Chamaremos essa abordagem de <em>força bruta</em>.</p>
</div>
<div id="forca-bruta" class="section level2">
<h2><span class="header-section-number">4.2</span> Força-bruta</h2>
<p>A abordagem de força bruta utiliza redes neurais convolucionais. Para explicar o funcionamento dessa técnica, vamos primeiro apresentar definições para redes neurais e para a operação de convolução. Em seguida, vamos juntar os dois conceitos para construir o modelo utilizado nos CAPTCHAs.</p>
<div id="redes-neurais" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Redes neurais</h3>
<p>Uma rede neural pode ser entendida como uma extensão de modelos lineares generalizados com a adição de uma arquitetura aos componentes do modelo. Para mostrar esse conceito, vamos partir da definição de um modelo regressão logística até construir uma rede neural com camadas ocultas.</p>
<div id="regressao-logistica" class="section level4">
<h4><span class="header-section-number">4.2.1.1</span> Regressão logística</h4>
<p>O modelo linear generalizado é composto por três elementos: componente aleatório, componente sistemático e função de ligação.</p>
<p>O componente aleatório é uma variável aleatória com distribuição pertencente à família exponencial, que dá origem à verossimilhança do modelo. O componente sistemático é uma combinação linear das variáveis preditoras com um vetor de parâmetros. A função de ligação é uma operação que leva a componente sistemática no valor esperado da componente aleatória. Uma forma comum de definir a ligação é propondo uma função com domínio nos números reais e contradomínio igual ao suporte do componente aleatório. Dessa forma, não é necessário impor restrições aos parâmetros da componente sistemática para que os valores ajustados variem na mesma faixa que o componente aletório.</p>
<div class="figure">
<img src="imgs/glm.png" />

</div>
<p>No exemplo da regressão logística, o componente aleatório tem distribuição Bernoulli com média <span class="math inline">\(\mu\)</span>. O componente sistemático é a combinação linear <span class="math inline">\(\mathbf X \boldsymbol \beta\)</span> e a função de ligação é a inversa de</p>
<p><span class="math display">\[
g(\mu) = \log\left(\frac{\mu}{1-\mu}\right)
\]</span></p>
<p>A partir de uma amostra <span class="math inline">\(y_1, \dots, \y_n\)</span> e observando que <span class="math inline">\(\mu_i = g^{-1}(\mathbf X_i\boldsymbol\beta)\)</span>, a verossimilhança do modelo é dada por</p>
<p><span class="math display">\[
\mathcal L(\boldsymbol \beta|\mathbf y) = \prod_{i=1}^n f(y_i|\boldsymbol\beta) = \prod_{i=1}^n\mu_i^{y_i}(1-\mu_i)^{1-y_i}
\]</span></p>
<p>A log-verossimilhança é dada por</p>
<p><span class="math display">\[
l(\boldsymbol \beta|\mathbf y) = \sum_{i=1}^n y_i\log(\mu_i) + (1-y_i)\log(1-\mu_i)
\]</span></p>
<p>Uma forma útil de olhar para a verossimilhança é a partir da <em>função desvio</em>, dada por</p>
<p><span class="math display">\[
D(\mathbf y|\boldsymbol \beta) = l(\mathbf y|\mathbf y) - l(\boldsymbol \beta|\mathbf y),
\]</span></p>
<p>onde <span class="math inline">\(l(\mathbf y|\mathbf y)\)</span> é a verossimilhança do modelo saturado, ou seja, calculada com <span class="math inline">\(\mathbf y\)</span> no lugar de <span class="math inline">\(\boldsymbol \mu\)</span>. A partir de um modelo ajustado, a função desvio pode ser interpretada como a distância entre a verossimilhança do modelo ajustado e a verossimilhança do modelo com um parâmetro para cada observação.</p>
<p>Uma propriedade interessante da função desvio é que ela equivale à divergência de Kullback-Leibler [@…]. Por exemplo, para duas variáveis aleatórias com distribuição Bernoulli de parâmetros <span class="math inline">\(p\)</span> e <span class="math inline">\(q\)</span>, respectivamente, a divergência de Kullback-Leibler é dada por</p>
<p><span class="math display">\[
D_{KL}(p||q) = p\log\left(\frac p q\right) + (1-p)\log\left(\frac{1-p}{1-q}\right)
\]</span></p>
<p>É fácil ver que</p>
<p><span class="math display">\[
\begin{align}
D(\mathbf y|{ \boldsymbol \beta}) &amp;= \sum_{i=1}^n y_i\log(y_i) + (1-y_i)\log(1-y_i) - \sum_{i=1}^n y_i\log(\mu_i) + (1-y_i)\log(1-\mu_i) \\
&amp;=\sum_{i=1}^ny_i\log\left(\frac{y_i}{\mu_i}\right) + (1-y_i)\log\left(\frac{1-y_i}{1-\mu_i}\right) \\
&amp;= \sum_{i=1}^n D_{KL}(y_i||\mu_i) \\
&amp;= D_{KL}(\mathbf y||{\boldsymbol\mu}).
\end{align}
\]</span></p>
<p>Outra propriedade interessante é que o desvio identifica unicamente a verossimilhança do modelo. De fato, podemos reformular a definição do modelo linear generalizado a partir da especificação do desvio ou da divergência de Kullback-Leibler no lugar do componente aleatório. Essa propriedade será útil na comparação com redes neurais.</p>
<p>Os estimadores de máxima verossimilhança de <span class="math inline">\(\boldsymbol \beta\)</span> são os mesmos que minimizam a função desvio. Graças à concavidade da divergência de Kullback-Leibler [@…], Isso pode ser feito igualando os componentes do gradiente do desvio a zero e isolando os valores de <span class="math inline">\(\boldsymbol \beta\)</span>:</p>
<p><span class="math display">\[
\nabla_{\boldsymbol \beta} D(\mathbf y|{ \boldsymbol \beta}) = \mathbf 0
\]</span></p>
<p>Como não é possível realizar essa operação analiticamente, utilizamos métodos iterativos. Existem dois principais métodos iterativos concorrentes: a descida de gradiente [@…] e o método de Newton-Raphson [@…]. No paradigma de modelos lineares generalizados, o método de Newton-Raphson é mais comum pois i) ele utiliza a segunda derivada e converge mais rápido que o método da descida de gradiente, que utiliza somente a primeira e ii) é possível demonstrar que ele equivale à aplicação iterada de <em>mínimos quadrados ponderados</em> [@…], o que facilita significativamente a implementação da solução. No paradigma de redes neurais, a descida de gradiente é mais comum por conta das vantagens <em>backpropagation</em>, que veremos na próxima subseção.</p>
<p>Em resumo, podemos concluir que</p>
<ol style="list-style-type: decimal">
<li>Um modelo linear generalizado pode ser definido por três componentes: a divergência de Kullback-Leibler, o preditor linear e a função de ligação.</li>
<li>A estimação dos parâmetros do modelo é realizada via descida de gradiente ou Newton-Raphson.</li>
</ol>
<p>Em seguida, veremos que a rede neural aparece quando utilizamos o componente sistemático e a função de ligação várias vezes.</p>
</div>
<div id="extensao-para-redes-neurais" class="section level4">
<h4><span class="header-section-number">4.2.1.2</span> Extensão para redes neurais</h4>
<p>Uma forma de estender o modelo linear generalizado é considerando que o resultado da função de ligação aplicada ao componente sistemático é uma nova covariável <span class="math inline">\(z\)</span>. Assim, temos</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf z &amp;= g^{-1}(\mathbf X \boldsymbol \beta)\\
\boldsymbol\mu &amp;= g^{-1}(\alpha_2\mathbf 1 + \beta_2 \mathbf z) = g^{-1}([\mathbf 1\;\mathbf z]\boldsymbol\beta_2),
\end{aligned}
\]</span></p>
<p>em que <span class="math inline">\(\boldsymbol\beta_2 = [\alpha_2\;\beta_2]^{\top}\)</span>. Agora, podemos aumentar o número de covariáveis <span class="math inline">\(\mathbf z\)</span> para <span class="math inline">\(k\)</span> covariáveis, de modo que</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf z_j &amp;= g^{-1}(\mathbf X \boldsymbol \beta_1^j)\\
\boldsymbol\mu &amp;= g^{-1}(\mathbf Z\boldsymbol\beta_2),
\end{aligned}
\]</span></p>
<p>onde <span class="math inline">\(\mathbf Z = [\mathbf 1\;\mathbf z_1\;\dots\;\mathbf z_k]\)</span>. O modelo espeficiado dessa forma também é chamado de <em>multilayer perceptron</em>, ou MLP [@…].</p>
<p>Mesmo com essa mudança, função desvio permanece a mesma, já que construída a partir de <span class="math inline">\(\boldsymbol \mu\)</span>. A única diferença é que agora ela é uma função de <span class="math inline">\(\boldsymbol \beta_1^j\)</span>, <span class="math inline">\(j=1,\dots,k\)</span> e <span class="math inline">\(\beta_2\)</span>. O ajuste do modelo é realizado da mesma forma:</p>
<p><span class="math display">\[
\nabla_{\{\boldsymbol \beta_1^1, \dots,\boldsymbol \beta_1^k,\boldsymbol \beta_2\}} D(\mathbf y|{ \boldsymbol \beta_1^1, \dots,\boldsymbol \beta_1^k,\boldsymbol \beta_2}) = \mathbf 0
\]</span></p>
<p>A vantagem dessa extensão é que adicionamos não linearidade ao modelo. Isso nos permite modelar relações mais complexas entre as preditoras e a resposta, o que pode resultar em melhores predições. De fato, é possível demonstrar que uma rede neural com uma camada oculta pode estima qualquer função contínua entre <span class="math inline">\(\mathbf X\)</span> e <span class="math inline">\(\mathbf y\)</span> [@…]. A desvantagem é que a estimação via Newton-Raphson é complicada de calcular.</p>
<p>É nesse momento que aparecem as vantagens da descida de gradiente. Primeiro, defina <span class="math inline">\(\boldsymbol \beta = \{\boldsymbol \beta_1^1, \dots,\boldsymbol \beta_1^k,\boldsymbol \beta_2\}\)</span>. Utilizando a regra da cadeia, a derivada parcial da função desvio em relação a <span class="math inline">\(\beta_{1,l}^{j}\)</span> é dado por</p>
<p><span class="math display">\[
\frac{\partial D(\mathbf y|\boldsymbol\beta)}{\partial \beta_{1,l}^{j}} = \sum_{i=1}^n\frac{\partial D(\mathbf y|\boldsymbol\beta)}{\partial z_{j,i}} \frac{\partial z_{j,i}}{\partial \beta_{1,l}^{j}} .
\]</span></p>
<p>As derivadas em relação aos elementos de <span class="math inline">\(\boldsymbol \beta_2\)</span> ocorrem diretamente, como na especificação em apenas um nível. Todas essas derivadas são fáceis de calcular e têm forma analítica definida. A aplicação da regra da cadeia de forma iterada nesse contexto é chamada de <em>backpropagation</em>.</p>
</div>
<div id="sinonimos-e-generalizacoes" class="section level4">
<h4><span class="header-section-number">4.2.1.3</span> Sinônimos e generalizações</h4>
<p>A literatura de redes neurais costuma trocar o nome função de ligação por <em>ativação</em>. Isso ocorre por motivos históricos, já que as redes neurais foram inicialmente inspiradas na ativação de sinapses de neurônios. No contexto de redes neurais, o objetivo da função de ativação não é, necessariamente, modificar a faixa de variação do contradomínio, pois o resultado após a função pode ser uma nova covariável. Isso sugere a existência de certa liberdade na escolha de ativações. A única restrição é que a função de ativação deve ser não linear, pois, se fosse linear, a aplicação de várias camadas de funções resultaria numa única combinação linear. As ativações mais populares são aquelas que têm derivadas simples.</p>
<p>Já a escolha do componente aleatório é substituída por uma <em>função de perda</em>. A natureza probabilística do modelo é considerada indiretamente através da função desvio, como vimos anteriormente. No entanto, ao invés de trabalhar com o desvio, os pesquisadores de redes neurais definem genericamente uma função de perda que mensura uma discrepância entre os valores observados e estimados. Uma escolha razoável de função de perda é a própria divergência de Kullback-Leibler, calculada com base no suporte da variável resposta, gerando a função desvio. No entanto, dependendo da aplicação, podemos escolher outras perdas, que podem gerar distribuições de probabilidades sem formato analítico específico.</p>
<p>Por último, a aplicação de camadas de não-linearidades podem ser representadas através de um grafo direcionado acíclico. Essa representação é vantajosa por dois motivos. O primeiro é que a aplicação facilita a especificação e entendimento do modelo e seus parâmetros, que podem ficar com notação carregada na especificação por fórmulas matemáticas. A segunda é que é possível utilizar conhecimentos de teoria dos grafos para aumentar a eficiência dos algoritmos. Por exemplo, é possível aproveitar parte dos cálculos do <em>backpropagation</em> na obtenção das derivadas parciais da função de perda <span class="citation">(<span class="citeproc-not-found" data-reference-id="tensorflow"><strong>???</strong></span>)</span>.</p>
<p>Em resumo, podemos concluir que</p>
<ol style="list-style-type: decimal">
<li>Uma rede neural é uma extensão de modelos lineares generalizados que aplica combinações lineares e funções de ligação de forma iterada.</li>
<li>A estimação dos parâmetros é realizada por descida de gradiente, explorando as vantagens do backpropagation.</li>
<li>Funções de ligação são chamadas de funções de ativação.</li>
<li>A função desvio é substituída por funções de perda mais gerais.</li>
<li>A aplicação iterada de operações pode ser representada por um grafo direcionado acíclico.</li>
</ol>
<p>Existem diversas formas de definir, desenhar e apresentar os conceitos básicos de redes neurais e a descida de gradiente. As melhores são apresentadas em blogs, vídeos e aplicativos, onde as operações são apresentadas de forma interativa. O racional apresentado nesse texto buscou mostrar a relação intrínseca entre a regressão logística e as redes neurais.</p>
</div>
</div>
<div id="a-operacao-de-convolucao" class="section level3">
<h3><span class="header-section-number">4.2.2</span> A operação de convolução</h3>
<p>Convolução em imagens é uma operação usada há muito tempo nas áreas de <em>visão computacional</em> e <em>processamento de sinais</em>. Ela geralmente é utilizada para detectar padrões e aplicar filtros em imagens. Basicamente, o que ela faz é calcular um novo valor para um pixel da imagem com base nos pixels da vizinhança. Por exemplo, você pode fazer com que o pixel <span class="math inline">\((i,j)\)</span> da sua imagem seja atualizado pela soma ponderada dos valores dos pixels na vizinhança.</p>
<p>Uma forma esperta de fazer essa soma ponderada é criando uma matriz de pesos: dessa forma, você não precisa ficar procurando os pontos da vizinhança. Para cada ponto <span class="math inline">\((i,j)\)</span>, você pega o subset da matriz de vizinhança, multiplica pontualmente pela matriz de pesos e soma todos os valores. Isso é <em>exatamente</em> o que a convolução faz.</p>
<p>Daqui em diante, chamaremos essa matriz de pesos de <strong>kernel</strong>. Considere esse exemplo 3x3:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kern_horizontal &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>),
                         <span class="kw">c</span>( <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>),
                         <span class="kw">c</span>( <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>))
kern_horizontal</code></pre></div>
<p>E considere essa imagem super complexa:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="st">&quot;imgs/emoji3.png&quot;</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>magick<span class="op">::</span><span class="kw">image_read</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">plot</span>()</code></pre></div>
<p>Na prática, essa imagem é isso aqui (tirei algumas linhas e colunas):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">emoji &lt;-<span class="st"> </span>decryptr<span class="op">:::</span><span class="kw">load_image</span>(<span class="st">&quot;imgs/emoji3.png&quot;</span>)[,,<span class="dv">1</span>] 
<span class="kw">round</span>(emoji, <span class="dv">1</span>)[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">12</span>]</code></pre></div>
<p>Tome por exemplo o ponto <span class="math inline">\((i,j) = (12,16)\)</span>. A vizinhança 3x3 em torno desse ponto é dada por</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">emoji[<span class="dv">12</span> <span class="op">+</span><span class="st"> </span>(<span class="op">-</span><span class="dv">1</span>)<span class="op">:</span><span class="dv">1</span>, <span class="dv">16</span> <span class="op">+</span><span class="st"> </span>(<span class="op">-</span><span class="dv">1</span>)<span class="op">:</span><span class="dv">1</span>]</code></pre></div>
<p>A operação de convolução é feita da seguinte forma:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(emoji[<span class="dv">12</span> <span class="op">+</span><span class="st"> </span>(<span class="op">-</span><span class="dv">1</span>)<span class="op">:</span><span class="dv">1</span>, <span class="dv">16</span> <span class="op">+</span><span class="st"> </span>(<span class="op">-</span><span class="dv">1</span>)<span class="op">:</span><span class="dv">1</span>] <span class="op">*</span><span class="st"> </span>kern_horizontal)</code></pre></div>
<p>Pronto, esse é o valor a ser colocado no ponto <span class="math inline">\((i,j)\)</span>. Fazemos isso para todos os outros pontos. Algumas dúvidas que podem rolar nesse ponto:</p>
<p>Com base nisso, montamos um algoritmo que faz a conta para todos os pixels, já criando uma borda na imagem:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">convolve &lt;-<span class="st"> </span><span class="cf">function</span>(img, kern) {
  <span class="co"># monta a bordinha na imagem. A borda deve ter (tamanho kernel) / 2,</span>
  <span class="co"># de tamanho, arredondando para baixo</span>
  pad &lt;-<span class="st"> </span><span class="kw">floor</span>(<span class="kw">dim</span>(kern)[<span class="dv">1</span>] <span class="op">/</span><span class="st"> </span><span class="dv">2</span>)
  img_pad &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow =</span> <span class="kw">nrow</span>(img) <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pad, <span class="dt">ncol =</span> <span class="kw">ncol</span>(img) <span class="op">+</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pad)
  img_pad[pad <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(img), pad <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(img)] &lt;-<span class="st"> </span>img[,,<span class="dv">1</span>]
  <span class="co"># aplica a convolução nos pontos da imagem</span>
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_len</span>(<span class="kw">nrow</span>(img))) {
    <span class="cf">for</span> (j <span class="cf">in</span> <span class="kw">seq_len</span>(<span class="kw">ncol</span>(img))) {
      img[i, j, <span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">sum</span>(img_pad[i <span class="op">+</span><span class="st"> </span><span class="dv">0</span><span class="op">:</span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pad), j <span class="op">+</span><span class="st"> </span><span class="dv">0</span><span class="op">:</span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>pad)] <span class="op">*</span><span class="st"> </span>kern)
    }
  }
  img[,,<span class="dv">2</span>] &lt;-<span class="st"> </span>img[,,<span class="dv">3</span>] &lt;-<span class="st"> </span>img[,,<span class="dv">1</span>]
  img
}</code></pre></div>
<p>Voltando para nossa imagem agora. No nosso caso, o resultado fica assim:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="st">&quot;imgs/emoji3.png&quot;</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>decryptr<span class="op">:::</span><span class="kw">load_image</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">convolve</span>(kern_horizontal) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>magick<span class="op">::</span><span class="kw">image_read</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">plot</span>()</code></pre></div>
<p>Ficou um pouco assustador, não? Essa matriz não foi escolhida por acaso. Ela serve para destacar padrões horizontais da imagem. Como a primeira linha é formada <code>-1</code>s e a última é formada por <code>1</code>s, a matriz fica com valor alto se a parte de cima do pixel for preta e a parte de baixo for branca (<code>grande * 1 + pequeno * (-1)</code>). A parte destacada da imagem acabou sendo os olhos (pois temos maior concentração de pixels pretos ali), além das extremidades superior e inferior do rosto.</p>
<p>Com esse kernel aqui (vertical), a parte destacada do rosto são as extremidades dos lados:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kern_vertical &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>),
                       <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>),
                       <span class="kw">c</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>))
kern_vertical

<span class="st">&quot;imgs/emoji3.png&quot;</span> <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>decryptr<span class="op">:::</span><span class="kw">load_image</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">convolve</span>(kern_vertical) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>magick<span class="op">::</span><span class="kw">image_read</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">plot</span>()</code></pre></div>
</div>
<div id="aplicando-nos-captchas" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Aplicando nos captchas</h3>
<p>Não tem segredo! Basta reaplicar o que já vimos. Vou apenas introduzir uma nova função chamada <code>add_bias()</code>, que simplesmente adiciona uma constante numérica para a matriz. Isso pode auxiliar na visualização, pois controlamos melhor os valores que ficam dentro do intervalo <code>[0,1]</code>. Lá na frente você entenderá o porquê do “bias”.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">add_bias &lt;-<span class="st"> </span><span class="cf">function</span> (x, b) x <span class="op">+</span><span class="st"> </span>b</code></pre></div>
<p>Esse é o resultado de adicionar o kernel vertical e bias de <code>0.6</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">arq &lt;-<span class="st"> &quot;imgs/captcha41367a06c5a.png&quot;</span></code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">op &lt;-<span class="st"> </span>graphics<span class="op">::</span><span class="kw">par</span>(<span class="dt">mar =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">4</span>))
arq <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>decryptr<span class="op">:::</span><span class="kw">load_image</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">convolve</span>(kern_vertical) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">add_bias</span>(.<span class="dv">6</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>magick<span class="op">::</span><span class="kw">image_read</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">plot</span>()</code></pre></div>
<p>Agora o kernel na horizontal. Note que identificamos padrões das linhas horizontais que tentam atrapalhar a visão das letras.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">op &lt;-<span class="st"> </span>graphics<span class="op">::</span><span class="kw">par</span>(<span class="dt">mar =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">4</span>))
arq <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>decryptr<span class="op">:::</span><span class="kw">load_image</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">convolve</span>(kern_horizontal) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">add_bias</span>(.<span class="dv">6</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>magick<span class="op">::</span><span class="kw">image_read</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">plot</span>()</code></pre></div>
<p>Colocando um após o outro, temos um resultado bem esquisito:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">op &lt;-<span class="st"> </span>graphics<span class="op">::</span><span class="kw">par</span>(<span class="dt">mar =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">4</span>))
arq <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>decryptr<span class="op">:::</span><span class="kw">load_image</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">convolve</span>(kern_horizontal) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">convolve</span>(kern_vertical) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">add_bias</span>(.<span class="dv">5</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>magick<span class="op">::</span><span class="kw">image_read</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">plot</span>()</code></pre></div>
<p>Também vou introduzir uma função chamada <code>relu()</code> aqui. <strong>ReLu</strong> significa <em>Restricted Linear Unit</em> e é uma função bem simples que zera tudo aquilo que é negativo e mantém tudo aquilo que é positivo. Assim, temos:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">relu &lt;-<span class="st"> </span><span class="cf">function</span>(x) (x <span class="op">+</span><span class="st"> </span><span class="kw">abs</span>(x)) <span class="op">/</span><span class="st"> </span><span class="dv">2</span>
<span class="kw">relu</span>(<span class="op">-</span><span class="dv">1</span>)
<span class="kw">relu</span>( <span class="dv">3</span>)</code></pre></div>
<p>Para visualização, essa função não serve para muita coisa, pois já fazemos a substituição de valores negativos por zero. No entanto, podemos fazer combos com a aplicação de várias convoluções. O resultado dos combos não seria possível somente com somas e multiplicações.</p>
<p>Na prática, isso significa que com a aplicação de convoluções, bias e ReLu, podemos montar operações <strong>não lineares</strong> para extrair componentes da imagem.</p>
<p>Olhe o exemplo abaixo. Parece que consegui identificar bem as coisas que são inúteis na imagem.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">op &lt;-<span class="st"> </span>graphics<span class="op">::</span><span class="kw">par</span>(<span class="dt">mar =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">4</span>))
arq <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>decryptr<span class="op">:::</span><span class="kw">load_image</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="co"># primeira convolucao</span>
<span class="st">  </span><span class="kw">convolve</span>(kern_horizontal) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">add_bias</span>(<span class="op">-</span>.<span class="dv">25</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">relu</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="co"># segunda convolucao</span>
<span class="st">  </span><span class="kw">convolve</span>(kern_vertical) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">add_bias</span>(.<span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>magick<span class="op">::</span><span class="kw">image_read</span>() <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">plot</span>()</code></pre></div>
<p>Isso tudo nos leva a pensar: será que eu consigo pensar em kernels que me ajudem a identificar as letras de uma forma razoável?</p>
</div>
<div id="redes-neurais-convolucionais" class="section level3">
<h3><span class="header-section-number">4.2.4</span> Redes neurais convolucionais</h3>
</div>
</div>
<div id="eficiencia-e-generalizacao" class="section level2">
<h2><span class="header-section-number">4.3</span> Eficiência e generalização</h2>
<p>A modelagem via redes neurais convolucionais apresenta resultados satisfatórios, mas tem dois problemas: eficiência e generalização.</p>
<p>O problema de eficiência está relacionado com o fato de que a quantidade de imagens classificadas necessária para obter bom poder preditivo é alta. A partir de nossos testes, identificamos que são necessários em torno de dez mil imagens classificadas para obter um modelo com taxa de acerto maior que 90%.</p>
<p>Já o problema de generalização implica que um modelo ajustado para um tipo CAPTCHA não funciona para outro, ainda que esses tipos sejam muito similares. Na verdade, esses modelos sofrem do problema de <em>aprender</em> versus <em>decorar</em> <span class="citation">(Zhang et al. <a href="#ref-zhang2016understanding">2016</a>)</span>. Isso significa que pequenas modificações na imagem original, e.g. inclusão de ruído gaussiano na imagem, podem resultar em predições completamente diferentes.</p>
<p>Os dois problemas não são independentes. Se criarmos um modelo que generaliza, é razoável afirmar que a quantidade de dados necessária para se obter bom poder preditivo numa nova imagem se reduz.</p>
<p>A Tabela <a href="#tab:solucoes"><strong>??</strong></a> mostra algumas possíveis abordagens para resolver esses problemas.</p>
<table>
<thead>
<tr class="header">
<th align="left">Eficiência</th>
<th align="left">Generalização</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Feedback</td>
<td align="left">Ensemble</td>
</tr>
<tr class="even">
<td align="left">Reciclagem</td>
<td align="left">Ruído</td>
</tr>
<tr class="odd">
<td align="left">Enriquecimento</td>
<td align="left"></td>
</tr>
</tbody>
</table>
<div id="feedback" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Feedback</h3>
</div>
<div id="reciclagem" class="section level3">
<h3><span class="header-section-number">4.3.2</span> Reciclagem</h3>
</div>
<div id="ensemble" class="section level3">
<h3><span class="header-section-number">4.3.3</span> Ensemble</h3>
</div>
<div id="section" class="section level3">
<h3><span class="header-section-number">4.3.4</span> </h3>
<ul>
<li>Ensemble</li>
<li>Data augmentation / geradores</li>
<li>Tesseract</li>
<li>Feedback</li>
<li>manual</li>
<li>oráculo</li>
</ul>

</div>
</div>
</div>
<h3> CAPTCHAs em áudio</h3>
<div id="refs" class="references">
<div id="ref-von2002telling">
<p>Ahn, Louis von, Manuel Blum, and John Langford. 2002. “Telling Humans and Computers Apart Automatically or How Lazy Cryptographers Do Ai.” <em>Computer Science Department</em>, 149.</p>
</div>
<div id="ref-von2003captcha">
<p>Von Ahn, Luis, Manuel Blum, Nicholas J Hopper, and John Langford. 2003. “CAPTCHA: Using Hard Ai Problems for Security.” In <em>International Conference on the Theory and Applications of Cryptographic Techniques</em>, 294–311. Springer.</p>
</div>
<div id="ref-mori2003recognizing">
<p>Mori, Greg, and Jitendra Malik. 2003. “Recognizing Objects in Adversarial Clutter: Breaking a Visual Captcha.” In <em>Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 Ieee Computer Society Conference on</em>, 1:I–I. IEEE.</p>
</div>
<div id="ref-yan2008low">
<p>Yan, Jeff, and Ahmad Salah El Ahmad. 2008a. “A Low-Cost Attack on a Microsoft Captcha.” In <em>Proceedings of the 15th Acm Conference on Computer and Communications Security</em>, 543–54. ACM.</p>
</div>
<div id="ref-yan2008usability">
<p>Yan, Jeff, and Ahmad Salah El Ahmad. 2008b. “Usability of Captchas or Usability Issues in Captcha Design.” In <em>Proceedings of the 4th Symposium on Usable Privacy and Security</em>, 44–52. ACM.</p>
</div>
<div id="ref-golle2008machine">
<p>Golle, Philippe. 2008. “Machine Learning Attacks Against the Asirra Captcha.” In <em>Proceedings of the 15th Acm Conference on Computer and Communications Security</em>, 535–42. ACM.</p>
</div>
<div id="ref-motoyama2010re">
<p>Motoyama, Marti, Kirill Levchenko, Chris Kanich, Damon McCoy, Geoffrey M Voelker, and Stefan Savage. 2010. “Re: CAPTCHAs-Understanding Captcha-Solving Services in an Economic Context.” In <em>USENIX Security Symposium</em>, 10:3.</p>
</div>
<div id="ref-bursztein2011text">
<p>Bursztein, Elie, Matthieu Martin, and John Mitchell. 2011. “Text-Based Captcha Strengths and Weaknesses.” In <em>Proceedings of the 18th Acm Conference on Computer and Communications Security</em>, 125–38. ACM.</p>
</div>
<div id="ref-bursztein2014end">
<p>Bursztein, Elie, Jonathan Aigrain, Angelika Moscicki, and John C Mitchell. 2014. “The End Is Nigh: Generic Solving of Text-Based Captchas.” In <em>WOOT</em>.</p>
</div>
<div id="ref-breiman2001random">
<p>Breiman, Leo. 2001. “Random Forests.” <em>Machine Learning</em> 45 (1). Springer: 5–32.</p>
</div>
<div id="ref-zhang2016understanding">
<p>Zhang, Chiyuan, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. 2016. “Understanding Deep Learning Requires Rethinking Generalization.” <em>arXiv Preprint arXiv:1611.03530</em>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="problema.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="resultados.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/yihui/bookdown-crc/edit/master/03-solution.Rmd",
"text": "Edit"
},
"download": ["jtrecenti_doctorate_captcha.pdf", "jtrecenti_doctorate_captcha.epub"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
